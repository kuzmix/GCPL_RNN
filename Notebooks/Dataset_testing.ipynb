{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"For google colab workflow - mounts Google Drive and go to it\"\"\"\n",
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "os.chdir('./gdrive/MyDrive/Projects/RNN_for_GCPL/Notebooks')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\"\"\"Imports all necessary libs\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import sklearn\n",
    "from Code.setup import *\n",
    "import datetime as dt\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from RNN_for_GCPL import setup\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "seedEverything(seed=DEFAULT_RANDOM_SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T14:21:18.903164400Z",
     "start_time": "2023-06-16T14:21:09.365661600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\"\"\"For compatibility - cd to folder with data and models\"\"\"\n",
    "os.chdir('../../RNN_for_GCPL/')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T14:21:18.903164400Z",
     "start_time": "2023-06-16T14:21:18.886731600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def check_correct_range(cycle:dict, correct_range:dict):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        cycle (): Cycle from resampled dataset, dictionary\n",
    "        correct_range (): Range for selected keys, in notation {key:(min, max)}\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    check_results = {key : np.all((cycle[key]>range[0]) & (cycle[key]<range[1])) for key, range in correct_range.items()}\n",
    "    return check_results\n",
    "\n",
    "\n",
    "def segmentation(current:np.array):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        current (np.array): Current from experiment cycle\n",
    "\n",
    "    Returns: segmentation - list of points for each segment\n",
    "\n",
    "    \"\"\"\n",
    "    cc_charge = np.nonzero(np.isclose(current, 75 / 150, atol=1 / 150))[0]\n",
    "    discharge = np.nonzero(np.isclose(current, -75 / 150, atol=1 / 150))[0]\n",
    "    cv_charge = np.nonzero((current > 7.4 / 150) & (current < 74 / 150))[0]\n",
    "    if cc_charge.shape[0] >0 and discharge.shape[0] >0:\n",
    "        cv_charge = cv_charge[(cv_charge > cc_charge.max()) & (cv_charge < discharge.min())]\n",
    "    rest_1 = np.nonzero(np.isclose(current, 0, atol=0.1 / 150))[0]\n",
    "    if cv_charge.shape[0] >0 and discharge.shape[0] >0:\n",
    "        rest_1 = rest_1[(rest_1 < discharge.min()) & (rest_1 > cv_charge.max())]\n",
    "    rest_2 = np.nonzero(np.isclose(current, 0, atol=0.1 / 150))[0]\n",
    "    if discharge.shape[0] > 0:\n",
    "        rest_2 = rest_2[rest_2 > discharge.max()]\n",
    "    else:\n",
    "        rest_2 = rest_2[np.isin(rest_2, rest_1, invert=True)]\n",
    "    segments = [cc_charge, cv_charge, rest_1, discharge, rest_2]\n",
    "    return segments\n",
    "\n",
    "\n",
    "def find_bad_cycles(dataset_full:torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        dataset_full (Dataset):\n",
    "\n",
    "    Returns: list of dicts, cleared dataset.\n",
    "\n",
    "    \"\"\"\n",
    "    soh, info = statistics(dataset_full)\n",
    "    broken_cycles = set()\n",
    "    correct_range = {'I':(-76/150, 76/150), 'E':(-0.01/1.45, 1+ .01/1.45)}\n",
    "    range_error = {key:[] for key in correct_range} #Values out of correct range\n",
    "    zero_size_error = {i:[] for i in range(5)} #Some segments have zero size\n",
    "    not_unite_error = {i:[] for i in range(5)} #Some segments are not all together\n",
    "    unknown_values_error = {'Below zero':[], 'High values':[]} #Different\n",
    "    all_segments = []\n",
    "    undefined_length = []\n",
    "    gaps_between_segments = {i:[] for i in range(6)}\n",
    "    for cycle_number in info.index.to_numpy():\n",
    "        cycle = dataset_full[cycle_number]\n",
    "        check_results = check_correct_range(cycle, correct_range)\n",
    "        for key, result in check_results.items():\n",
    "            if not result:\n",
    "                range_error[key].append(cycle_number)\n",
    "\n",
    "        current = cycle[\"I\"]\n",
    "        segments = segmentation(current)\n",
    "        undefined_length.append(len(current)-np.sum([len(i) for i in segments]))\n",
    "        all_segments.append(segments)\n",
    "        # max_segment=0\n",
    "        for i, segment in enumerate(segments):\n",
    "            # gaps_between_segments[i].append(segment.min()- max_segment)\n",
    "            # max_segment = segment.max()\n",
    "            if segment.shape[0] == 0:\n",
    "                zero_size_error[i].append(cycle_number)\n",
    "            elif segment.ptp()- segment.shape[0]>0:\n",
    "                not_unite_error[i].append(cycle_number)\n",
    "        # gaps_between_segments[5].append(len(current) - max_segment)\n",
    "    undefined_length = np.array(undefined_length)\n",
    "    unknown_values_error['Below zero'] = np.where((undefined_length<0))[0]\n",
    "    unknown_values_error['High values'] =np.where((undefined_length>=35*30/sampling_size))[0]\n",
    "    for i in range_error.values():\n",
    "        broken_cycles.update(i)\n",
    "    for i in zero_size_error.values():\n",
    "        broken_cycles.update(i)\n",
    "    for i in not_unite_error.values():\n",
    "        broken_cycles.update(i)\n",
    "    for i in unknown_values_error.values():\n",
    "        broken_cycles.update(i)\n",
    "    # gaps_between_segments = np.array([i for i in gaps_between_segments.values()])\n",
    "    all_pouches = info.groupby('Pouch').count()['SoH']\n",
    "    short_pouches = all_pouches[all_pouches<50].index\n",
    "    short_pouches_cycles = info[info.Pouch.isin(short_pouches)].index.tolist()\n",
    "    broken_cycles.update(short_pouches_cycles)\n",
    "    high_temp_cycles = info[info.Filename.str.contains('T50', case=False)].index\n",
    "    broken_cycles.update(high_temp_cycles)\n",
    "    refilled_cycles = info[info.Filename.str.contains('ref', case=False)].index\n",
    "    broken_cycles.update(refilled_cycles)\n",
    "    print(len(broken_cycles))\n",
    "    return broken_cycles"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T14:32:20.942898400Z",
     "start_time": "2023-06-16T14:32:20.906273300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3793\n"
     ]
    }
   ],
   "source": [
    "sampling_size = 30\n",
    "dataset_full_path = os.path.normpath(fr'./data/v5/{sampling_size}/')\n",
    "dataset_full = GCPL_dataset_resampled3(dataset_full_path)\n",
    "broken_cycles = find_bad_cycles(dataset_full)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T14:34:05.175410500Z",
     "start_time": "2023-06-16T14:32:23.287258500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "for sampling_size in [30, 60, 120, 180, 300]:\n",
    "    dataset_full_path = os.path.normpath(fr'./data/v5/{sampling_size}/')\n",
    "    dataset_full = GCPL_dataset_resampled3(dataset_full_path)\n",
    "    dataset_full.data = [cycle for i, cycle in enumerate(dataset_full) if i not in broken_cycles]\n",
    "    dataset_full.save(os.path.normpath(fr'./data/v6/{sampling_size}/'), overwrite=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T14:34:16.251151500Z",
     "start_time": "2023-06-16T14:34:05.175410500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
